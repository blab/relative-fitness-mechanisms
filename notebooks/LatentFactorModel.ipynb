{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53653442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '../relative_fitness_mechanisms/' )\n",
    "import plot_utils\n",
    "from latent_immunity_relative_fitness import RelativeFitnessDR, LatentRW, LatentSplineRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"xtick.labelsize\"] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import jit, lax\n",
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import evofr as ef\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_seq = pd.read_csv(\"../../evofr/test/testing_data/mlr-variant-counts.tsv\", sep=\"\\t\")\n",
    "#raw_seq = raw_seq[raw_seq.location == \"City0\"]\n",
    "#data = ef.VariantFrequencies(raw_seq, pivot=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_seq = pd.read_csv(\"../../rt-from-frequency-dynamics/data/variants-us/variants-us_location-variant-sequence-counts.tsv\", sep=\"\\t\")\n",
    "#raw_seq\n",
    "#data = ef.VariantFrequencies(raw_seq)\n",
    "#data = ef.HierFrequencies(raw_seq, group=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_seq = pd.read_csv(\"../../HHMI_poster/data/seq_counts_nextstrain_clades_usa.tsv.gz\", sep=\"\\t\").rename(columns={\"clade\": \"variant\"})\n",
    "#raw_seq = pd.read_csv(\"../../HHMI_poster/data/seq_counts_pango_lineages_usa.tsv.gz\", sep=\"\\t\").rename(columns={\"clade\": \"variant\"})\n",
    "\n",
    "raw_seq = pd.read_csv(\"../data/pango-lineage/collapsed-sequence-counts-global.tsv\", sep=\"\\t\")\n",
    "#TODO: Collapsing on pango data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75275b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = \"2023-03-01\"\n",
    "date_end = \"2024-06-01\"\n",
    "\n",
    "raw_seq = raw_seq[raw_seq.date < date_end].copy()\n",
    "raw_seq = raw_seq[raw_seq.date > date_start].copy()\n",
    "\n",
    "data = ef.HierFrequencies(raw_seq, group=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccc631",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_variants = raw_seq.variant.unique()\n",
    "print(f\"There are {len(unique_variants)} variants\")\n",
    "print(unique_variants)\n",
    "\n",
    "unique_locations = raw_seq.location.unique()\n",
    "print(f\"There are {len(unique_locations)} locations\")\n",
    "print(unique_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evofr.plotting import FrequencyPlot, GrowthAdvantagePlot, TimeVaryingPlot, PatchLegend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a85071",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = False\n",
    "load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding proper latent dim\n",
    "latent_dim_candidates = np.arange(2, 13)\n",
    "num_candidates = len(latent_dim_candidates)\n",
    "posteriors = {}\n",
    "if infer:\n",
    "    for i, latent_dim in enumerate(latent_dim_candidates):\n",
    "        print(f\"Fitting K = {latent_dim}. ({i+1}/{num_candidates})\")\n",
    "        phi_model = LatentSplineRW(ef.Spline(order=4, k=6))\n",
    "        model = RelativeFitnessDR(dim=latent_dim, phi_model=phi_model, hier=True)\n",
    "        #inference_method = ef.InferNUTS(num_samples=500, num_warmup=500)\n",
    "        inference_method = ef.InferMAP(lr=4e-4, iters=30_000)\n",
    "        posteriors[latent_dim] = inference_method.fit(model, data=data)\n",
    "        posteriors[latent_dim].save_posterior(f\"../results/posteriors/latent-factor-analysis/latent_factor_{latent_dim}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = {}\n",
    "if load:\n",
    "    for i, latent_dim in enumerate(latent_dim_candidates):\n",
    "        posteriors[latent_dim] = ef.PosteriorHandler(data=data)\n",
    "        posteriors[latent_dim].load_posterior(f\"../results/posteriors/latent-factor-analysis/latent_factor_{latent_dim}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2109a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final losses by model\n",
    "if \"losses\" in posteriors[latent_dim_candidates[0]].samples.keys():\n",
    "    fig = plt.figure(figsize=(6., 4.), constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=1, nrows=1)\n",
    "    ax = fig.add_subplot(spec[0])\n",
    "    \n",
    "    losses = {dim: post.samples[\"losses\"][-1] for dim, post in posteriors.items()}\n",
    "    ax.plot(losses.keys(), losses.values(), zorder=-1, color=\"lightgrey\")\n",
    "    ax.scatter(losses.keys(), losses.values(), ec=\"k\", s=60, color=\"red\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Latent dimension\")\n",
    "    ax.set_xticks([2,4,6, 8, 10, 12])\n",
    "    \n",
    "#    fig.savefig(\"../manuscript/supplementary_figures/loss_by_latent_dimension.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_latent = 8\n",
    "posterior = posteriors[chosen_latent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"losses\" in posterior.samples.keys():\n",
    "    fig = plt.figure(figsize=(6., 4.), constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=1, nrows=1)\n",
    "    ax = fig.add_subplot(spec[0])\n",
    "    ax.plot(posterior.samples[\"losses\"])\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(samples, sites, group):\n",
    "    samples_group = dict()\n",
    "    for site in sites:\n",
    "        samples_group[site] = samples[site][..., group] \n",
    "    return samples_group\n",
    "\n",
    "def get_posterior(posterior, sites, group):\n",
    "    _samples = get_groups(posterior.samples, sites, group)\n",
    "    _data = posterior.data.groups[group]\n",
    "    return ef.PosteriorHandler(samples=_samples, data=_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = posterior.samples[\"eta\"][0,:,:]\n",
    "eta_transformed = MDS(normalized_stress=\"auto\").fit_transform(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab01729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_geo_phi_embedding(posterior):\n",
    "    fig = plt.figure(figsize=(12., 12.), constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=2, nrows=3, height_ratios=[0.7, 0.7, 0.3])\n",
    "\n",
    "    ax_explained = fig.add_subplot(spec[-2:])\n",
    "\n",
    "    phi = posterior.samples[\"phi\"][0, ...]\n",
    "    \n",
    "    # We want to collapse first three columns basically\n",
    "    new_shape = (-1, phi.shape[-1])\n",
    "    long_phi = np.reshape(phi, new_shape)\n",
    "    \n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit(long_phi.T)\n",
    "    \n",
    "    # Plot locations\n",
    "    phi_transformed = pca.transform(long_phi.T)\n",
    "    def plot_pca_dims(ax, X_transformed, dim1, dim2):\n",
    "        ax.scatter(X_transformed[:, dim1], X_transformed[:, dim2], ec=\"k\", s=120)\n",
    "        ax.set_xlabel(f\"PCA {dim1+1}\")\n",
    "        ax.set_ylabel(f\"PCA {dim2+1}\")\n",
    "        # Annotate\n",
    "        for i, txt in enumerate(posterior.data.names):\n",
    "            ax.annotate(txt, (X_transformed[i, dim1], X_transformed[i, dim2]), size=14, weight=\"bold\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ax = fig.add_subplot(spec[0])\n",
    "    plot_pca_dims(ax, phi_transformed, 0, 1)\n",
    "    \n",
    "    ax = fig.add_subplot(spec[1])\n",
    "    plot_pca_dims(ax, phi_transformed, 0, 2)\n",
    "\n",
    "    ax = fig.add_subplot(spec[2])\n",
    "    plot_pca_dims(ax, phi_transformed, 0, 3)\n",
    "    \n",
    "    ax = fig.add_subplot(spec[3])\n",
    "    plot_pca_dims(ax, phi_transformed, 0, 4)\n",
    "\n",
    "    \n",
    "    # Plot variance explained\n",
    "    var_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "    ax_explained.bar(np.arange(var_explained.shape[0])+1, var_explained, ec=\"k\", color=\"pink\")\n",
    "    ax_explained.set_xticks(np.arange(var_explained.shape[0])+1)\n",
    "    ax_explained.set_xlabel(\"Component\")\n",
    "    ax_explained.set_ylabel(\"% Variance explained\")\n",
    "    ax_explained.set_xlim((0, 11))\n",
    "    ax_explained.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax_explained.axhline(y=0.8, color=\"k\", linestyle=\"--\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "plot_geo_phi_embedding(posterior)\n",
    "\n",
    "# TODO: Color by continent and show as supplementary figure\n",
    "# Which are the most anamolous\n",
    "# Are there \"natural\" clusters here? What are they?\n",
    "# Are these well-explained by air travel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8857549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geo_phi_embedding(posterior):\n",
    "    fig = plt.figure(figsize=(12., 8.), constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=2, nrows=2)\n",
    "    phi = posterior.samples[\"phi\"][0, ...]\n",
    "    \n",
    "    # We want to collapse first three columns basically\n",
    "    new_shape = (-1, phi.shape[-1])\n",
    "    long_phi = np.reshape(phi, new_shape)\n",
    "    \n",
    "    mds = MDS(10, normalized_stress=True, metric=False,random_state=12)\n",
    "    phi_transformed = mds.fit_transform(long_phi.T)\n",
    "    print(phi_transformed.shape)\n",
    "    # Plot locations\n",
    "    def plot_mds_dims(ax, X_transformed, dim1, dim2):\n",
    "        ax.scatter(X_transformed[:, dim1], X_transformed[:, dim2], ec=\"k\", s=120)\n",
    "        ax.set_xlabel(f\"MDS {dim1+1}\")\n",
    "        ax.set_ylabel(f\"MDS {dim2+1}\")\n",
    "        # Annotate\n",
    "        for i, txt in enumerate(posterior.data.names):\n",
    "            ax.annotate(txt, (X_transformed[i, dim1], X_transformed[i, dim2]), size=14, weight=\"bold\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ax = fig.add_subplot(spec[0])\n",
    "    plot_mds_dims(ax, phi_transformed, 0, 1)\n",
    "    ax = fig.add_subplot(spec[1])\n",
    "    plot_mds_dims(ax, phi_transformed, 1, 2)\n",
    "    ax = fig.add_subplot(spec[2])\n",
    "    plot_mds_dims(ax, phi_transformed, 2, 3)\n",
    "    ax = fig.add_subplot(spec[3])\n",
    "    plot_mds_dims(ax, phi_transformed, 3, 4)\n",
    "\n",
    "    return mds\n",
    "    \n",
    "    \n",
    "mds = plot_geo_phi_embedding(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pango_aliasor.aliasor import Aliasor\n",
    "\n",
    "antigenic_map = pd.concat([pd.read_csv(\"../data/antigenic_map_data/immunized human.csv\"), \n",
    "                           pd.read_csv(\"../data/antigenic_map_data/naive human.csv\")])\n",
    "antigenic_map.columns\n",
    "\n",
    "# For each variant in posterior, check\n",
    "# 1. if it was tested directly (ignore)\n",
    "# 2. its parent was tested (consider renaming)\n",
    "# 3. its parent is not already directly observed (do not rename)\n",
    "\n",
    "remapping = {}\n",
    "aliasor = Aliasor()\n",
    "for var in posterior.data.var_names:\n",
    "    parent = aliasor.parent(var)\n",
    "    if (parent in antigenic_map.columns) and (var not in antigenic_map.columns) and (parent not in posterior.data.var_names):\n",
    "        remapping[parent] = var\n",
    "\n",
    "# For each variant in antigenic map, check\n",
    "# 1. check whether we estimated pseudo-escape for its parent but not directly\n",
    "# 2. check whether parent is directly observed (do not rename)\n",
    "# 3. That we have not already renamed\n",
    "# 4. Avoid long brannches -> avoid collapsing BA.1, BA.2, BA.5\n",
    "\n",
    "for var in antigenic_map.columns:\n",
    "    parent = aliasor.parent(var)\n",
    "    if ((parent in posterior.data.var_names) \n",
    "        and (var not in posterior.data.var_names) \n",
    "        and (parent not in antigenic_map.columns)\n",
    "        and (var not in remapping)\n",
    "        and (parent not in [\"B.1.1.529\"])\n",
    "       ):\n",
    "        remapping[var] = parent\n",
    "\n",
    "        \n",
    "antigenic_map = antigenic_map.rename(columns=remapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80bf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65674fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "antigenic_map = antigenic_map.rename(columns=remapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antigenic_map_melt = antigenic_map.melt([\"id\", \"group\"], var_name=\"strain\", value_name=\"NT50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antigenic_map_melt.strain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log2_distances(X):\n",
    "    X_transformed = np.log2(X.values)\n",
    "    return np.sqrt(np.sum(np.square(X_transformed.T[..., None] - X_transformed), axis=1))\n",
    "\n",
    "def create_titer_distance_df(X):\n",
    "    rows = []\n",
    "    for i, v in enumerate(X.columns):\n",
    "        for j, u in enumerate(X.columns[:(i+1)]):\n",
    "            rows.append({\"variant_1\": v, \"variant_2\": u, \"titer_distance\": distances[i, j]})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "X = antigenic_map.drop(columns=[\"id\", \"group\"])\n",
    "distances = compute_log2_distances(X)\n",
    "distances_df = create_titer_distance_df(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=2, nrows=1)\n",
    "\n",
    "def plot_mds_dims(ax, X_transformed, dim1, dim2):\n",
    "        ax.scatter(X_transformed[:, dim1], X_transformed[:, dim2], ec=\"k\", s=120)\n",
    "        ax.set_xlabel(f\"MDS {dim1+1}\")\n",
    "        ax.set_ylabel(f\"MDS {dim2+1}\")\n",
    "        # Annotate\n",
    "        for i, txt in enumerate(X.columns):\n",
    "            ax.annotate(txt, (X_transformed[i, dim1], X_transformed[i, dim2]), size=14, weight=\"bold\")\n",
    "        return None\n",
    "\n",
    "mds = MDS(n_components=3, normalized_stress=\"auto\", random_state=12)\n",
    "X_transformed = mds.fit_transform(np.log2(X.values.T))\n",
    "\n",
    "ax = fig.add_subplot(spec[0])\n",
    "plot_mds_dims(ax, X_transformed, 0, 1 )\n",
    "ax = fig.add_subplot(spec[1])\n",
    "plot_mds_dims(ax, X_transformed, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd110e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variants = [v for v in posterior.data.var_names if v in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for v in posterior.data.var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d314fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(distances_df.variant_1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd336a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "fig = plt.figure(figsize=(12., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(1,2)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "\n",
    "def get_and_add_distances(post, _distance_df):\n",
    "    distance_df = _distance_df.copy()\n",
    "    \n",
    "    ## Prepping data and labels\n",
    "    eta = post.samples[\"eta\"][0, :-1, :] # Remove other\n",
    "    n_vars, n_comps = eta.shape\n",
    "\n",
    "    eta_distances = jnp.sqrt(jnp.sum(jnp.square(eta[..., None] - eta.T), axis=1))\n",
    "    var_names = post.data.var_names\n",
    "    var_to_index = {v: i for i, v in enumerate(var_names)}        \n",
    "\n",
    "    def add_latent_distance(row):\n",
    "        if row[\"variant_1\"] in common_variants and row[\"variant_2\"] in common_variants:\n",
    "            return float(eta_distances[var_to_index[row[\"variant_1\"]], var_to_index[row[\"variant_2\"]]])\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    distance_df[\"latent_distance\"] = distance_df.apply(add_latent_distance, axis=1)\n",
    "    return distance_df\n",
    "\n",
    "X = antigenic_map.drop(columns=[\"id\", \"group\"])\n",
    "distances = compute_log2_distances(X)\n",
    "distances_df = create_titer_distance_df(X)\n",
    "distances_df = get_and_add_distances(posteriors[chosen_latent], distances_df)\n",
    "distances_df = distances_df[distances_df.variant_1 != distances_df.variant_2]\n",
    "\n",
    "# Fit linear regression\n",
    "def fit_linear(col1, col2):\n",
    "    x, y = distances_df[col1], distances_df[col2]\n",
    "    is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[is_finite], y[is_finite]\n",
    "    slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "    xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "    ys = intercept + slope * xs\n",
    "    return xs, ys, r, p\n",
    "\n",
    "x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "x, y = distances_df[x_col], distances_df[y_col]\n",
    "ax.scatter(x, y, ec=\"k\")       \n",
    "\n",
    "# Fit linear regression between two variables\n",
    "xs, ys, r, p = fit_linear(x_col, y_col)\n",
    "ax.plot(xs, ys, color=\"k\")\n",
    "\n",
    "# Add regression statistics\n",
    "ax.text(0.2, 0.985, f'R^2: {(r ** 2).round(4)} \\np: {p.round(5)}',\n",
    "        horizontalalignment='right',\n",
    "        verticalalignment='top',\n",
    "        transform=ax.transAxes)\n",
    "ax.set_xlabel(\"Pseudo-Escape Distance\")\n",
    "ax.set_ylabel(\"log2 Human NT50 Titer Distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f33a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's boostrap the correlation and R^2 here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def bootstrap_regression(n_bootstrap):\n",
    "    x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "    x, y = distances_df[x_col], distances_df[y_col]\n",
    "\n",
    "    r2s = []\n",
    "    rs = []\n",
    "    ps = []\n",
    "    expected = []\n",
    "    \n",
    "    def fit_linear(col1, col2):\n",
    "        x, y = distances_df[col1], distances_df[col2]\n",
    "        is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "        \n",
    "        # Boostrap for present data\n",
    "        n_finite = np.sum(is_finite)\n",
    "        sample = np.random.choice(n_finite, n_finite, replace=True)\n",
    "                \n",
    "        # Fit regression\n",
    "        x, y = x[is_finite].values[sample], y[is_finite].values[sample]\n",
    "        slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "        xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "        ys = intercept + slope * xs\n",
    "        return xs, ys, r, p\n",
    "\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Fit linear regression\n",
    "        xs, ys, r, p = fit_linear(x_col, y_col) \n",
    "        \n",
    "        expected.append((xs,ys))\n",
    "        r2s.append(r**2)\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    return r2s, rs, ps, expected\n",
    "\n",
    "# Example usage\n",
    "r2_bootstrap, r_bootstrap, p_bootstrap, expected_bootstrap = bootstrap_regression(n_bootstrap=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 10.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(2, 2, height_ratios=[0.2, 0.8])\n",
    "\n",
    "# Bootstrapped R^2\n",
    "ax_r2 = fig.add_subplot(spec[0])\n",
    "ax_r2.hist(r2_bootstrap, color=\"lightgrey\", ec=\"k\", bins=20)\n",
    "ax_r2.set_xlabel(r\"$R^2$\")\n",
    "ax_r2.set_ylabel(\"Count\")\n",
    "\n",
    "# Bootrapped r\n",
    "ax_r = fig.add_subplot(spec[1])\n",
    "ax_r.hist(r_bootstrap, color=\"lightgrey\", ec=\"k\", bins=20)\n",
    "ax_r.set_xlabel(r\"$r$\")\n",
    "ax_r.set_ylabel(\"Count\")\n",
    "print((np.array(r_bootstrap) > 0).sum())\n",
    "ax_expected = fig.add_subplot(spec[1, :])\n",
    "x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "x, y = distances_df[x_col], distances_df[y_col]\n",
    "for xs, ys in expected_bootstrap:\n",
    "    ax_expected.plot(xs, ys, alpha=0.2, color=\"lightgrey\", zorder=-1)       \n",
    "ax_expected.scatter(x, y, ec=\"k\", color=\"#474747\", s=240)      \n",
    "\n",
    "ax_expected.set_xlabel(\"Pseudo escape distance\")\n",
    "ax_expected.set_ylabel(\"log2 Human titer distance\")\n",
    "\n",
    "# Add labels\n",
    "ax_labels = [\"A\", \"B\", \"C\"] \n",
    "\n",
    "for ax, ax_label in zip([ax_r2, ax_r, ax_expected], ax_labels):\n",
    "    ax.text(-0.1, 1.1, ax_label + \".\", transform=ax.transAxes, size=36, weight='bold')\n",
    "\n",
    "fig.savefig(\"../manuscript/supplementary_figures/pseudo_escape_titer_correlation_bootstrap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(r_bootstrap) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_definitions = [\n",
    "    {\n",
    "        \"clade\": \"24B\",\n",
    "        \"display_name\": \"24B (JN.1.11.1)\",\n",
    "        \"defining_lineage\": \"JN.1.11.1\",\n",
    "        \"color\": '#DC2F24'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"24A\",\n",
    "        \"display_name\": \"24A (JN.1)\",\n",
    "        \"defining_lineage\": \"JN.1\",\n",
    "        \"color\": '#E4632E'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23I\",\n",
    "        \"display_name\": \"23I (BA.2.86)\",\n",
    "        \"defining_lineage\": \"BA.2.86\",\n",
    "        \"color\": '#E69136'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23H\",\n",
    "        \"display_name\": \"23H (HK.3)\",\n",
    "        \"defining_lineage\": \"HK.3\",\n",
    "        \"color\": '#D9AD3D'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23G\",\n",
    "        \"display_name\": \"23G (XBB.1.5.70)\",\n",
    "        \"defining_lineage\": \"XBB.1.5.70\",\n",
    "        \"color\": '#C1BA47'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23F\",\n",
    "        \"display_name\": \"23F (EG.5.1)\",\n",
    "        \"defining_lineage\": \"EG.5.1\",\n",
    "        \"color\": '#A2BE57'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23E\",\n",
    "        \"display_name\": \"23E (XBB.2.3)\",\n",
    "        \"defining_lineage\": \"XBB.2.3\",\n",
    "        \"color\": '#83BA70'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23D\",\n",
    "        \"display_name\": \"23D (XBB.1.9)\",\n",
    "        \"defining_lineage\": \"XBB.1.9\",\n",
    "        \"color\": '#69B091'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23C\",\n",
    "        \"display_name\": \"23C (CH.1.1)\",\n",
    "        \"defining_lineage\": \"CH.1.1\",\n",
    "        \"color\": '#549DB2'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23B\",\n",
    "        \"display_name\": \"23B (XBB.1.16)\",\n",
    "        \"defining_lineage\": \"XBB.1.16\",\n",
    "        \"color\": '#4580CA'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"23A\",\n",
    "        \"display_name\": \"23A (XBB.1.5)\",\n",
    "        \"defining_lineage\": \"XBB.1.5\",\n",
    "        \"color\": '#462EB9'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"22F\",\n",
    "        \"display_name\": \"22F (XBB)\",\n",
    "        \"defining_lineage\": \"XBB\",\n",
    "        \"color\": '#3E58CF'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"22E\",\n",
    "        \"display_name\": \"22E (BQ.1)\",\n",
    "        \"defining_lineage\": \"BQ.1\",\n",
    "        \"color\": '#777777'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"22D\",\n",
    "        \"display_name\": \"22D (BA.2.75)\",\n",
    "        \"defining_lineage\": \"BA.2.75\",\n",
    "        \"color\": '#777777'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"22B\",\n",
    "        \"display_name\": \"22B (BA.5)\",\n",
    "        \"defining_lineage\": \"BA.5\",\n",
    "        \"color\": '#777777'\n",
    "    },\n",
    "    {\n",
    "        \"clade\": \"other\",\n",
    "        \"display_name\": \"other\",\n",
    "        \"defining_lineage\": False,\n",
    "        \"color\": '#777777'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685391dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pango_aliasor.aliasor import Aliasor\n",
    "import colorsys\n",
    "\n",
    "DEFAULT_CLADE_COLOR = '#777777'\n",
    "def order_lineages(lineages, aliasor):\n",
    "    \"\"\"\n",
    "    Order input lineages by using their full uncompressed lineage & converting to a sortable form\n",
    "    e.g. BA.5  -> B.1.1.529.5  -> '  B/001/001/529/005'\n",
    "         BA.16 -> B.1.1.529.16 -> '  B/001/001/529/016'\n",
    "         so BA.5 is before BA.16\n",
    "    \"\"\"\n",
    "    def _lineage_sortable(lineage):\n",
    "        if lineage=='other':\n",
    "            return \"ZZZ\"\n",
    "        lin_full = aliasor.uncompress(lineage)\n",
    "        return \"/\".join([(f\"{x:>3}\" if i==0 else f\"{int(x):03}\") for i,x in enumerate(lin_full.split('.'))])\n",
    "    return sorted(lineages,key=_lineage_sortable)\n",
    "\n",
    "def order_lineages_within_clade(lineages, aliasor, clade_map):\n",
    "    \"\"\"\n",
    "    Order input lineages by their clades first and then by using their full uncompressed lineage,\n",
    "    converting to a sortable form within each clade.\n",
    "\n",
    "    Parameters:\n",
    "    lineages (list of str): List of lineage names to be sorted.\n",
    "    aliasor (object): An object with a method `uncompress` that converts compressed lineage names to full lineage names.\n",
    "    clades (list of str): List of clade assignments corresponding to each lineage.\n",
    "\n",
    "    Returns:\n",
    "    list of str: Sorted list of lineage names.\n",
    "\n",
    "    Example:\n",
    "    >>> class Aliasor:\n",
    "    ...     def uncompress(self, lineage):\n",
    "    ...         return {\"BA.5\": \"B.1.1.529.5\", \"BA.16\": \"B.1.1.529.16\", \"BA.2\": \"B.1.1.529.2\"}[lineage]\n",
    "    >>> aliasor = Aliasor()\n",
    "    >>> lineages = [\"BA.5\", \"BA.16\", \"BA.2\"]\n",
    "    >>> clades = [\"Clade1\", \"Clade1\", \"Clade2\"]\n",
    "    >>> order_lineages(lineages, aliasor, clades)\n",
    "    ['BA.5', 'BA.16', 'BA.2']\n",
    "    \"\"\"\n",
    "\n",
    "    def _lineage_sortable(lineage):\n",
    "        if lineage == 'other':\n",
    "            return \"ZZZ\"\n",
    "        lin_full = aliasor.uncompress(lineage)\n",
    "        return \"/\".join([(f\"{x:>3}\" if i == 0 else f\"{int(x):03}\") for i, x in enumerate(lin_full.split('.'))])\n",
    "    \n",
    "    # Sort the lineages first by clade and then by the sortable form of the lineage\n",
    "    return sorted(lineages, key=lambda lineage: (clade_map[lineage], _lineage_sortable(lineage)))\n",
    "\n",
    "def lineage_to_clade(lineage, aliasor, fallback, clade_definitions):\n",
    "    lineage_full = aliasor.uncompress(lineage)\n",
    "    for clade_data in clade_definitions:\n",
    "        if clade_data['clade']=='other':\n",
    "            continue\n",
    "        comparison_lineage = aliasor.uncompress(clade_data['defining_lineage'])\n",
    "        if lineage_full == comparison_lineage or lineage_full.startswith(comparison_lineage + \".\"):\n",
    "            return clade_data['clade']\n",
    "    return fallback\n",
    "\n",
    "def clade_colors(variants, clade_definitions):\n",
    "    colors = {c['clade']: c['color'] for c in clade_definitions}\n",
    "    missing = set()\n",
    "    defs = []\n",
    "    for v in variants:\n",
    "        try:\n",
    "            defs.append([v, colors[v]])\n",
    "        except KeyError:\n",
    "            if v!='other':\n",
    "                missing.add(v)\n",
    "                defs.append([v, DEFAULT_CLADE_COLOR])\n",
    "\n",
    "    # TODO: Emit this to output file so it can be sent thru Slack notifications\n",
    "    if len(missing) > 0:\n",
    "        print(\n",
    "            f\"Missing definitions for the following clades: {', '.join(missing)}.\",\n",
    "            f\"They have been assigned the default color {DEFAULT_CLADE_COLOR!r}\"\n",
    "        )\n",
    "\n",
    "    return defs\n",
    "\n",
    "def clade_display_names(variants, clade_definitions):\n",
    "    display_names = {c['clade']: c['display_name'] for c in clade_definitions}\n",
    "    return [[name, display_names[name] if name in display_names else name]\n",
    "            for name in variants]\n",
    "\n",
    "def colour_range(anchor, n):\n",
    "    \"\"\"\n",
    "    Create a range of `n` colours centred around the provided `anchor`.\n",
    "    This currently involves simple manipulations in HLS space, but\n",
    "    the outputs aren't going to be as good as they could be if we did it in\n",
    "    a perceptually uniform space (e.g lab space). For the purposes of this viz\n",
    "    I don't think it's a dealbreaker, and in our current setup it's hard to use\n",
    "    python libraries which aren't already available in our various runtimes.\n",
    "    \"\"\"\n",
    "    anchor_rgb = tuple(int(anchor.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "    anchor_hls = colorsys.rgb_to_hls(*anchor_rgb)\n",
    "    hrange = np.linspace(anchor_hls[0]*0.85, anchor_hls[0]*1.25, n)\n",
    "    lrange = np.linspace(anchor_hls[1]*1.2, anchor_hls[1], n)\n",
    "    srange = np.linspace(anchor_hls[2]*0.7, anchor_hls[2]*1.1, n)\n",
    "    rgb_range = [colorsys.hls_to_rgb(*hls) for hls in zip(hrange, lrange, srange)]\n",
    "    def clamp(x):\n",
    "        return int(max(0, min(x, 255)))\n",
    "    return [f\"#{clamp(rgb[0]):02x}{clamp(rgb[1]):02x}{clamp(rgb[2]):02x}\" for rgb in rgb_range]\n",
    "\n",
    "def colourise(lineages, aliasor, clade_definitions):\n",
    "    \"\"\"\n",
    "    Produces an array of arrays associating observed lineages with a colour hex. Example output:\n",
    "        [\n",
    "            ['XBB', '#ffffff'],\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    clades = {lineage: lineage_to_clade(lineage, aliasor, 'other', clade_definitions)\n",
    "              for lineage in lineages}\n",
    "\n",
    "    colours = []\n",
    "\n",
    "    for clade in list(set(clades.values())):\n",
    "        matching_lineages = [l for l in lineages if clades[l]==clade] # will be ordered\n",
    "        print(f\"{clade:<10}n={len(matching_lineages)} lineages\")\n",
    "        color_hex = [x['color'] for x in clade_definitions if x['clade']==clade][0]\n",
    "        for pair in zip(matching_lineages, colour_range(color_hex, len(matching_lineages))):\n",
    "            colours.append(pair)\n",
    "    return colours\n",
    "\n",
    "aliasor = Aliasor()\n",
    "color_map = colourise(posterior.data.var_names, aliasor, clade_definitions)\n",
    "color_map = {entry[0]: entry[1] for entry in color_map}\n",
    "clade_map = {lineage: lineage_to_clade(lineage, aliasor, 'other', clade_definitions)\n",
    "              for lineage in posterior.data.var_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_color_map = clade_colors([c[\"clade\"] for c in clade_definitions], clade_definitions)\n",
    "clade_color_map = {c[0]: c[1] for c in clade_color_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f973f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aliasor.parent(\"KP.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "def get_ordering(var_names):\n",
    "    \n",
    "    #reordered_names = order_lineages(var_names, aliasor)[:-1]\n",
    "    reordered_names = order_lineages_within_clade(var_names, aliasor, clade_map)[:-1]\n",
    "    reordered_clades = [clade_map[n] for n in reordered_names]\n",
    "\n",
    "    reordered_idx = [var_names.index(r) for r in reordered_names]\n",
    "    return reordered_idx, reordered_names, reordered_clades\n",
    "    \n",
    "# Fit linear regression\n",
    "def fit_linear(col1, col2):\n",
    "    x, y = distances_df[col1], distances_df[col2]\n",
    "    is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[is_finite], y[is_finite]\n",
    "    slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "    xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "    ys = intercept + slope * xs\n",
    "    return xs, ys, r, p\n",
    "\n",
    "# Merge in latent distnances\n",
    "def add_latent_distance(row, var_to_index, eta_distances):\n",
    "    if row[\"variant_1\"] in common_variants and row[\"variant_2\"] in common_variants:\n",
    "        return float(eta_distances[var_to_index[row[\"variant_1\"]], var_to_index[row[\"variant_2\"]]])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def add_bracket(ax, start, end, label, y_offset=-0.1, height=0.02, **kwargs):\n",
    "    \"\"\"\n",
    "    Add a bracket below the x-axis labels to group them.\n",
    "\n",
    "    Parameters:\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes to add the bracket to.\n",
    "    start : int\n",
    "        The starting index of the grouped labels.\n",
    "    end : int\n",
    "        The ending index of the grouped labels.\n",
    "    label : str\n",
    "        The label for the bracket.\n",
    "    y_offset : float, optional\n",
    "        The vertical offset for the bracket (default is -0.1).\n",
    "    height : float, optional\n",
    "        The height of the bracket (default is 0.02).\n",
    "    kwargs : additional parameters for customization.\n",
    "    \"\"\"\n",
    "    ax.annotate('', xy=(start, y_offset), xytext=(end, y_offset),\n",
    "                arrowprops=dict(arrowstyle='<|-|>', lw=3.0, **kwargs))\n",
    "    ax.text((start + end) * 0.5, y_offset - height, label, fontsize=16, color=clade_color_map[label],\n",
    "            ha='center', va='center', **kwargs)\n",
    "    \n",
    "def add_clade_dividers(ax, reordered_clades, height=-0.4, y_offset=4.5):\n",
    "    current_clade = reordered_clades[0]\n",
    "    start = 0\n",
    "\n",
    "    for i in range(1, len(reordered_clades)):\n",
    "        if reordered_clades[i] != current_clade:\n",
    "            add_bracket(ax, start-0.5, i-0.5, current_clade, y_offset=y_offset, height=height)\n",
    "            current_clade = reordered_clades[i]\n",
    "            start = i\n",
    "            \n",
    "    # Add bracket for the last group\n",
    "    add_bracket(ax, start - 0.5, len(reordered_clades)-1 + 0.5, current_clade, y_offset=y_offset, height=height)\n",
    "        \n",
    "def summary_plot_hier(posterior, color_map,\n",
    "                      label_variants=None, \n",
    "                      focal_variants=None,\n",
    "                      focal_locations=None,\n",
    "                      freq_thres = None,\n",
    "                      plot_eta_time_mean=True):\n",
    "    fig = plt.figure(figsize=(28., 16.), constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=4, nrows=3, height_ratios=[1.0, 1.0, 1.3])\n",
    "    axes = []\n",
    "\n",
    "    # Prep variants to plot in panels <A-B>\n",
    "    if focal_variants is None:\n",
    "        focal_variants = [\"HK.3\", \"JN.1\", \"JN.1.1\"]\n",
    "    var_names = posterior.data.var_names\n",
    "    var_idxs = [var_names.index(v) if v in var_names else None for v in focal_variants]\n",
    "    \n",
    "    # Prep locations to plot in panel <A-B-C>\n",
    "    if focal_locations is None:\n",
    "        focal_locations = [\"USA\", \"United Kingdom\", \"Japan\"]\n",
    "    loc_names = posterior.data.names\n",
    "    loc_idxs = [loc_names.index(loc) if loc in loc_names else None for loc in focal_locations]\n",
    "    focal_style = {loc: [\"-\", \"--\", \":\"][l] for l, loc in enumerate(focal_locations)}\n",
    "    \n",
    "    # Prep colors for immunity components in panel <C>\n",
    "    immunity_colors = [\"#f8f9fa\",\"#e9ecef\",\"#dee2e6\",\"#ced4da\",\"#adb5bd\",\"#6c757d\",\"#495057\",\"#343a40\",\"#212529\"]\n",
    "    immunity_colors = [\"#797d62\",\"#9b9b7a\",\"#baa587\",\"#d9ae94\",\"#f1dca7\",\"#ffcb69\",\"#e8ac65\",\"#d08c60\",\"#b58463\",\"#997b66\", '#4D4D4D', '#B3B3B3']\n",
    "    num_pseudo_immune = posterior.samples[\"phi\"].shape[2]\n",
    "    pic_color_map = {n: immunity_colors[n] for n in range(num_pseudo_immune)}\n",
    "    \n",
    "    # Prep locations to annoate in panel E\n",
    "    if label_variants is None:\n",
    "        label_variants = [\"XBB.1.5\", \"EG.1\", \"HK.3\", \"JN.1\", \"JN.1.1\"]\n",
    "\n",
    "    # Get ordering and clades with pango_aliasor\n",
    "    reordered_idx, reordered_names, reordered_clades = get_ordering(var_names)\n",
    "    \n",
    "    # Only plot variant at times above `freq_thres`\n",
    "    if freq_thres is None:\n",
    "        freq_thres = 0.001\n",
    "\n",
    "    # Frequency\n",
    "    ax = fig.add_subplot(spec[0, 0:2])\n",
    "    for loc_idx, location in zip(loc_idxs, focal_locations):\n",
    "        for var_idx, variant in zip(var_idxs, focal_variants):\n",
    "            included = np.array((posterior.samples[\"freq\"][0, :, var_idx, loc_idx] > freq_thres))\n",
    "            ax.plot(np.array(posterior.data.dates)[included], posterior.samples[\"freq\"][0, :, var_idx, loc_idx][included], color=color_map[variant], linestyle=focal_style[location])\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b\\n%Y'))\n",
    "    axes.append(ax)\n",
    "        \n",
    "    # Add legend for focal variants\n",
    "    variant_color_elements =  [Patch(facecolor=color_map[v], edgecolor='k', label=v) for v in focal_variants]\n",
    "    location_style_elements = [Line2D([0], [0], color='k', lw=3, linestyle=focal_style[l], label=l) for l in focal_locations]\n",
    "    legend_elements = variant_color_elements + location_style_elements\n",
    "    ax.legend(handles=legend_elements, loc='best', ncols=2, frameon=False)\n",
    "\n",
    "    # Relative Fitness\n",
    "    ax = fig.add_subplot(spec[0, 2:4], sharex=ax)\n",
    "    for loc_idx, location in zip(loc_idxs, focal_locations):\n",
    "        for var_idx, variant in zip(var_idxs, focal_variants):\n",
    "            included = np.array((posterior.samples[\"freq\"][0, :, var_idx, loc_idx] > freq_thres))\n",
    "            ax.plot(np.array(posterior.data.dates)[included], posterior.samples[\"delta\"][0, :, var_idx, loc_idx][included], color=color_map[variant], linestyle=focal_style[location])\n",
    "    ax.set_ylabel(\"Relative Fitness\")\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b\\n%Y'))\n",
    "    axes.append(ax)\n",
    " \n",
    "\n",
    "    # Phi \n",
    "    ax = fig.add_subplot(spec[1, 0:2])\n",
    "    for loc_idx, location in zip(loc_idxs, focal_locations):\n",
    "        for pic in range(num_pseudo_immune):\n",
    "            ax.plot(posterior.data.dates, posterior.samples[\"phi\"][0, :, pic, loc_idx], color=pic_color_map[pic], linestyle=focal_style[location])\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b\\n%Y'))\n",
    "    ax.set_ylabel(\"Pseudo immunity\")\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "    # Add legend for PICs\n",
    "    pic_color_elements =  [Patch(facecolor=pic_color_map[pic], edgecolor='k', label=f\"PIC {pic+1}\") for pic in range(num_pseudo_immune)]\n",
    "    ax.legend(handles=pic_color_elements, loc='upper left', ncols=2, frameon=False)\n",
    "\n",
    "    axes.append(ax)\n",
    "    \n",
    "    # Eta\n",
    "    ## Prepping data and labels\n",
    "    eta = posterior.samples[\"eta\"][0, :-1, :] # Remove other\n",
    "    n_vars, n_comps = eta.shape\n",
    "    eta_reordered = eta.T[:, np.array(reordered_idx).astype(int)]\n",
    "    xticklabels_reordered = [posterior.data.var_names[:-1][r] for r in reordered_idx]\n",
    "    \n",
    "    # Plotting matrix of values\n",
    "    ax = fig.add_subplot(spec[2, :3])\n",
    "    im = ax.matshow(eta_reordered, cmap=\"bwr\")\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.set_xticks(np.arange(n_vars))\n",
    "    ax.set_xticklabels(xticklabels_reordered, rotation=90)\n",
    "    for xtick in ax.get_xticklabels():\n",
    "        xtick.set_color(color_map[xtick._text])\n",
    "    ax.tick_params(axis='x', bottom=False)\n",
    "\n",
    "    ax.set_yticks(np.arange(n_comps))\n",
    "    ax.set_yticklabels(np.arange(1, n_comps + 1))\n",
    "    ax.set_ylabel(\"Pseudo escape dim\")\n",
    "    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')    \n",
    "    axes.append(ax)\n",
    "    \n",
    "    ## Adding clade dividers\n",
    "    add_clade_dividers(ax, reordered_clades, height=-0.5, y_offset=n_comps-0.5)\n",
    "\n",
    "    # Plotting embedding variant space\n",
    "    mds = MDS(n_components=3, normalized_stress=\"auto\", random_state=12)\n",
    "    eta_scaled = (eta - eta.mean(axis=0)) / np.std(eta, axis=0)\n",
    "    eta_transformed = mds.fit_transform(eta_scaled)\n",
    "    \n",
    "    def _plot_mds_escape(ax, dim_1, dim_2, plot_time_mean=True):\n",
    "        ax.scatter(eta_transformed[:,dim_1], eta_transformed[:,dim_2], \n",
    "                   ec=\"k\", \n",
    "                   color=[color_map[v] for v in posterior.data.var_names[:-1]],\n",
    "                   s=240)\n",
    "        ax.set_xlabel(f\"Pseudo escape MDS {dim_1+1}\")\n",
    "        ax.set_ylabel(f\"Pseudo escape MDS {dim_2+1}\")   \n",
    "        \n",
    "        if plot_time_mean:\n",
    "            for loc_idx, location in zip(loc_idxs, focal_locations):\n",
    "                freq = posterior.samples[\"freq\"][0, :, :-1, loc_idx]\n",
    "                eta_transformed_time = (freq @ eta_transformed) # Average over variants\n",
    "                ax.plot(eta_transformed_time[:,dim_1], eta_transformed_time[:,dim_2], color=\"k\", linestyle=focal_style[location], lw=4)\n",
    "        \n",
    "        # Add names to variants\n",
    "        for i, txt in enumerate(posterior.data.var_names[:-1]):\n",
    "            if txt in label_variants + focal_variants:\n",
    "                ax.annotate(txt, (eta_transformed[i,dim_1], eta_transformed[i,dim_2]), rotation=0, size=14, weight=\"bold\", ha='center', va=\"center_baseline\")\n",
    "        return None\n",
    "    \n",
    "    ax = fig.add_subplot(spec[1,2])    \n",
    "    _plot_mds_escape(ax, 0, 1, plot_eta_time_mean)\n",
    "    axes.append(ax)\n",
    "\n",
    "    ax = fig.add_subplot(spec[1,3])\n",
    "    _plot_mds_escape(ax, 0, 2, plot_eta_time_mean)\n",
    "    axes.append(ax)\n",
    "    \n",
    "    # Add human titer comparison\n",
    "    ax = fig.add_subplot(spec[2,3])\n",
    "    eta_distances = jnp.sqrt(jnp.sum(jnp.square(eta[..., None] - eta.T), axis=1))\n",
    "    var_to_index = {v: i for i, v in enumerate(var_names)}        \n",
    "    distances_df[\"latent_distance\"] = distances_df.apply(lambda x: add_latent_distance(x, var_to_index, eta_distances), axis=1)\n",
    "\n",
    "    x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "    x, y = distances_df[x_col], distances_df[y_col]\n",
    "    ax.scatter(x, y, ec=\"k\", color=\"#474747\", s=240)      \n",
    "\n",
    "    # Fit linear regression between two variables\n",
    "    xs, ys, r, p = fit_linear(x_col, y_col)\n",
    "    ax.plot(xs, ys, color=\"k\")\n",
    "\n",
    "    # Add regression statistics\n",
    "    stats_text = r'$R^2$: ' + str((r ** 2).round(3)) +\"\\n\" r\"$p$: \" + str(p.round(5))\n",
    "\n",
    "    ax.text(0.2, 0.985, stats_text,\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            transform=ax.transAxes)\n",
    "    ax.set_xlabel(\"Pseudo escape distance\")\n",
    "    ax.set_ylabel(\"log2 Human Titer distance\")\n",
    "    axes.append(ax)\n",
    "\n",
    "    # Add labels\n",
    "    ax_labels = [\"A\", \"B\", \"C\", \"F\", \"D\", \"E\", \"G\"] \n",
    "\n",
    "    for ax, ax_label in zip(axes, ax_labels):\n",
    "        ax.text(-0.1, 1.1, ax_label + \".\", transform=ax.transAxes, size=36, weight='bold')\n",
    "    return fig\n",
    "\n",
    "fig = summary_plot_hier(posterior, color_map, freq_thres=0.005, \n",
    "                        focal_variants=[\"XBB.1.5\", \"BQ.1.1\", \"HV.1\", \"JN.1\"],\n",
    "                        label_variants=[\"XBB.1.5\", \"CH.1.1\", \"BQ.1.1\", \"JD.1.1\", \"EG.1\", \"HV.1\", \"JN.1\"],\n",
    "                        plot_eta_time_mean=False\n",
    "                       )\n",
    "fig.savefig(\"../manuscript/figures/\" + \"latent_immune.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed by location\n",
    "phi = posterior.samples[\"phi\"][0, :, :-1, :] # Remove other\n",
    "phi_scaled = (phi - phi.mean(axis=0)) / np.std(phi, axis=0)\n",
    "phi_scaled = jnp.reshape(phi_scaled, (-1, len(posterior.data.names)) )\n",
    "phi_transformed = mds.fit_transform(phi_scaled.T)\n",
    "    \n",
    "def _plot_mds_location(ax, dim_1, dim_2):\n",
    "    ax.scatter(phi_transformed[:,dim_1], phi_transformed[:,dim_2], \n",
    "                   ec=\"k\", \n",
    "                   color=\"white\",\n",
    "                   s=480)\n",
    "    ax.set_xlabel(f\"Pseudo immunity dim {dim_1+1}\")\n",
    "    ax.set_ylabel(f\"Pseudo immunity dim {dim_2+1}\")   \n",
    "                \n",
    "    # Add names to locations\n",
    "    for i, txt in enumerate(posterior.data.names):\n",
    "        ax.annotate(txt, (phi_transformed[i,dim_1], phi_transformed[i,dim_2]), rotation=0, size=14, weight=\"bold\", ha='center', va=\"center_baseline\")\n",
    "    return None\n",
    "    \n",
    "fig = plt.figure(figsize=(12., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=2, nrows=1)\n",
    "\n",
    "ax = fig.add_subplot(spec[0])\n",
    "_plot_mds_location(ax, 0, 1)\n",
    "\n",
    "ax = fig.add_subplot(spec[1])\n",
    "_plot_mds_location(ax, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18547476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_titer_distance_df(X):\n",
    "    rows = []\n",
    "    for i, v in enumerate(X.columns):\n",
    "        for j, u in enumerate(X.columns[:(i+1)]):\n",
    "            rows.append({\"variant_1\": v, \"variant_2\": u, \"titer_distance\": distances[i, j]})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "distances_dfs = []\n",
    "for name, group in antigenic_map.groupby(\"group\"):\n",
    "    X = group.drop(columns=[\"id\", \"group\"])\n",
    "    distances = compute_log2_distances(X)\n",
    "    _distance_df = create_titer_distance_df(X)\n",
    "    _distance_df[\"group\"] = name\n",
    "    distances_dfs.append(_distance_df)\n",
    "\n",
    "distances_dfs = pd.concat(distances_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62acd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "antigenic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24., 12.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(2,4)\n",
    "\n",
    "## Prepping data and labels\n",
    "eta = posterior.samples[\"eta\"][0, :-1, :] # Remove other\n",
    "n_vars, n_comps = eta.shape\n",
    "\n",
    "eta_distances = jnp.sqrt(jnp.sum(jnp.square(eta[..., None] - eta.T), axis=1))\n",
    "var_names = posterior.data.var_names\n",
    "var_to_index = {v: i for i, v in enumerate(var_names)}        \n",
    "\n",
    "def add_latent_distance(row):\n",
    "    if row[\"variant_1\"] in common_variants and row[\"variant_2\"] in common_variants:\n",
    "        return float(eta_distances[var_to_index[row[\"variant_1\"]], var_to_index[row[\"variant_2\"]]])\n",
    "    else:\n",
    "        return np.nan\n",
    "distances_dfs[\"latent_distance\"] = distances_dfs.apply(add_latent_distance, axis=1)\n",
    "distances_dfs = distances_dfs[distances_dfs.variant_1 != distances_dfs.variant_2]\n",
    "\n",
    "# Fit linear regression\n",
    "def fit_linear(df, col1, col2):\n",
    "    x, y = df[col1], df[col2]\n",
    "    is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[is_finite], y[is_finite]\n",
    "    slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "    xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "    ys = intercept + slope * xs\n",
    "    return xs, ys, r, p\n",
    "\n",
    "correlation_df = []\n",
    "for i, (name, group) in enumerate(distances_dfs.groupby(\"group\")):\n",
    "    ax = fig.add_subplot(spec[i])\n",
    "    x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "    x, y = group[x_col], group[y_col]\n",
    "    ax.scatter(x, y, ec=\"k\", color=\"#474747\", s=180)            \n",
    "\n",
    "    # Fit linear regression between two variables\n",
    "    xs, ys, r, p = fit_linear(group, x_col, y_col)\n",
    "    ax.plot(xs, ys, color=\"k\")\n",
    "\n",
    "    # Add regression statistics\n",
    "    stats_text = r'$R^2$: ' + str((r ** 2).round(3)) +\"\\n\" r\"$p$: \" + str(p.round(4))\n",
    "    ax.text(0.35, 0.985, stats_text,\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            transform=ax.transAxes, fontsize=24)\n",
    "    ax.set_xlabel(\"Pseudo escape distance\")\n",
    "    ax.set_ylabel(\"Titer distance (log2)\")\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    correlation_df.append({\"group\": name, \"R2\": r ** 2})\n",
    "    \n",
    "correlation_df = pd.DataFrame(correlation_df).sort_values(by=\"R2\")\n",
    "\n",
    "ax = fig.add_subplot(spec[-1])\n",
    "ax.bar(correlation_df.group, correlation_df.R2, ec=\"k\", color=\"lightgrey\")\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylabel(r\"$R^2$ with pseudo escape distance\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"../manuscript/supplementary_figures/titer_pseudo_escape_distance_by_group.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906467ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicates for main figure for selected K\n",
    "# Merge in latent distnances\n",
    "def add_latent_distance(row, var_to_index, eta_distances):\n",
    "    if row[\"variant_1\"] in common_variants and row[\"variant_2\"] in common_variants:\n",
    "        return float(eta_distances[var_to_index[row[\"variant_1\"]], var_to_index[row[\"variant_2\"]]])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# Fit linear regression\n",
    "def fit_linear(col1, col2):\n",
    "    x, y = distances_df[col1], distances_df[col2]\n",
    "    is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = x[is_finite], y[is_finite]\n",
    "    slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "    xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "    ys = intercept + slope * xs\n",
    "    return xs, ys, r, p\n",
    "\n",
    "for latent_dim in latent_dim_candidates[::2]:\n",
    "    if latent_dim == chosen_latent:\n",
    "        continue\n",
    "    fig = summary_plot_hier(posteriors[latent_dim], color_map, freq_thres=0.01, \n",
    "                        focal_variants=[\"XBB.1.5\", \"BQ.1.1\", \"HV.1\", \"JN.1\"],\n",
    "                        label_variants=[\"XBB.1.5\", \"CH.1.1\", \"BQ.1.1\", \"JD.1.1\", \"EG.1\", \"HV.1\", \"JN.1\"],\n",
    "                        plot_eta_time_mean=False\n",
    "                       )\n",
    "    fig.savefig(\"../manuscript/supplementary_figures/\" + f\"latent_immune_{latent_dim}_dims.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ed3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim_candidates[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0525df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_regression(n_bootstrap, distance_df):\n",
    "    x_col, y_col =  \"latent_distance\", \"titer_distance\"\n",
    "    \n",
    "    r2s = []\n",
    "    ps = []\n",
    "    expected = []\n",
    "    \n",
    "    def fit_linear(col1, col2):\n",
    "        x, y = distance_df[col1], distance_df[col2]\n",
    "        is_finite = ~np.isnan(x) & ~np.isnan(y)\n",
    "        \n",
    "        # Boostrap for present data\n",
    "        n_finite = np.sum(is_finite)\n",
    "        sample = np.random.choice(n_finite, n_finite, replace=True)\n",
    "                \n",
    "        # Fit regression\n",
    "        x, y = x[is_finite].values[sample], y[is_finite].values[sample]\n",
    "        slope, intercept, r, p, se = stats.linregress(x, y)      \n",
    "        xs = np.linspace(np.min(x), np.max(x), 20)\n",
    "        ys = intercept + slope * xs\n",
    "        return xs, ys, r, p\n",
    "\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Fit linear regression\n",
    "        xs, ys, r, p = fit_linear(x_col, y_col) \n",
    "        \n",
    "        expected.append((xs,ys))\n",
    "        r2s.append(r)\n",
    "        ps.append(p)\n",
    "    return r2s, ps, expected\n",
    "\n",
    "# Compute base distance df\n",
    "X = antigenic_map.drop(columns=[\"id\", \"group\"])\n",
    "distances = compute_log2_distances(X)\n",
    "distances_df = create_titer_distance_df(X)\n",
    "distances_df = distances_df[distances_df.variant_1 != distances_df.variant_2]\n",
    "\n",
    "dfs = {}\n",
    "r2s = {}\n",
    "for latent_dim, post in posteriors.items():\n",
    "    dfs[latent_dim] = get_and_add_distances(post, distances_df)\n",
    "    r2s[latent_dim], _, _ = bootstrap_regression(1_000,  dfs[latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ddd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfs[2] == dfs[5])[\"latent_distance\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c125e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[2][~pd.isna(dfs[2].latent_distance)].variant_1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(1,1)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "\n",
    "ax.boxplot(list(r2s.values()), labels=list(r2s.keys()))\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_ylabel(r\"$R^2$\" + \"\\nPseudo-immune and titer distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c069b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12., 12.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=2)\n",
    "\n",
    "axes = []\n",
    "\n",
    "ax = fig.add_subplot(spec[0]); axes.append(ax)\n",
    "losses = {dim: post.samples[\"losses\"][-1] for dim, post in posteriors.items()}\n",
    "ax.plot(losses.keys(), losses.values(), zorder=-1, color=\"lightgrey\")\n",
    "ax.scatter(losses.keys(), losses.values(), ec=\"k\", s=90, color=\"red\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    " \n",
    "# Violin plot\n",
    "ax = fig.add_subplot(spec[1]); axes.append(ax)\n",
    "ax.violinplot(list(r2s.values()), list(r2s.keys()))\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_ylabel(r\"$R^2$\" + \"\\nPseudo-immune and titer distance\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "\n",
    "\n",
    "ax_labels = [\"A\", \"B\", \"C\", \"F\", \"D\", \"E\", \"G\"] \n",
    "\n",
    "for ax, ax_label in zip(axes, ax_labels):\n",
    "    ax.text(-0.2, 1.05, ax_label + \".\", transform=ax.transAxes, size=36, weight='bold')\n",
    "\n",
    "#fig.savefig(\"../manuscript/supplementary_figures/loss_by_latent_dimension.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_count(posterior):\n",
    "    essential_sites = ['_phi_0_base', '_phi_0_rest', 'phi_rw_step', '_init_logit', '_eta']\n",
    "    parameter_count = 0\n",
    "    for site in essential_sites:\n",
    "        parameter_count += posterior.samples[site][0].size\n",
    "    return parameter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78935ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bases = posteriors[2].samples[\"phi_rw_step\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461690d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def guess_count(D): \n",
    "#    eta_count = (len(unique_variants) - 1) * D \n",
    "#    phi_count = len(unique_locations) * D  *  num_bases\n",
    "#    logit_count = len(unique_locations) * (len(unique_variants)-1)\n",
    "#    return eta_count + phi_count + logit_count\n",
    "    \n",
    "#guessed_count = [guess_count(D) for D in latent_dim_candidates]\n",
    "parameter_count = [get_parameter_count(posteriors[D]) for D in latent_dim_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6560b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlr_fixed_count():\n",
    "    fitness_count = len(unique_locations) * (len(unique_variants)-1)\n",
    "    logit_count = len(unique_locations) * (len(unique_variants)-1)\n",
    "    return fitness_count + logit_count\n",
    "\n",
    "def mlr_time_count():\n",
    "    fitness_count = len(unique_locations) * (len(unique_variants)-1) * num_bases\n",
    "    logit_count = len(unique_locations) * (len(unique_variants)-1)\n",
    "    return fitness_count + logit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12., 12.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=2)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "#ax.plot(latent_dim_candidates, parameter_count, zorder=-1, color=\"lightgrey\")\n",
    "ax.scatter(latent_dim_candidates, parameter_count, color=\"red\", ec=\"k\", s=120, label=\"Latent factor model\")\n",
    "ax.axhline(mlr_fixed_count(),linestyle=\"--\", color=\"#B3B3B3\", label=\"Fixed fitness\")\n",
    "ax.axhline(mlr_time_count(),linestyle=\"--\", color=\"#666666\", label=\"Time-varying fitness\")\n",
    "ax.set_ylabel(\"Number of parameters\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameter_count[chosen_latent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bic(posteriors, latent_dim_candidates):\n",
    "    num_datapoints = posteriors[latent_dim_candidates[0]].data.seq_counts.size\n",
    "    parameter_counts = [get_parameter_count(posteriors[D]) for D in latent_dim_candidates]\n",
    "    losses = [-posteriors[D].samples[\"losses\"][-1] for D in latent_dim_candidates] # loss = negative log likelhood\n",
    "    bic = np.array([float(np.log(num_datapoints) * k  - 2 * l) for k, l in zip(parameter_counts, losses)])\n",
    "    bic_min = np.min(bic)\n",
    "    prob_min_information_loss = np.exp((bic_min - bic) / 2)\n",
    "    \n",
    "    return bic, prob_min_information_loss\n",
    "\n",
    "bic, prob_min_information_loss = get_bic(posteriors, latent_dim_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12., 12.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=2)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "ax.scatter(latent_dim_candidates, bic, color=\"red\", ec=\"k\", s=90)\n",
    "ax.set_ylabel(\"BIC\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3918ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18., 12.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=2, nrows=2)\n",
    "\n",
    "axes = []\n",
    "\n",
    "# Loss by dimension\n",
    "ax = fig.add_subplot(spec[0]); axes.append(ax)\n",
    "losses = {dim: post.samples[\"losses\"][-1] for dim, post in posteriors.items()}\n",
    "ax.plot(losses.keys(), losses.values(), zorder=-1, color=\"lightgrey\")\n",
    "ax.scatter(losses.keys(), losses.values(), ec=\"k\", s=90, color=\"red\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    " \n",
    "# Violin plot\n",
    "ax = fig.add_subplot(spec[2]); axes.append(ax)\n",
    "parts = ax.violinplot(list(r2s.values()), list(r2s.keys()), showmeans=False, showmedians=False,\n",
    "        showextrema=False)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('lightgrey')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(1)\n",
    "    \n",
    "quantiles = [np.percentile(r2s[D], [25, 50, 75]) for D in latent_dim_candidates]\n",
    "ax.scatter(latent_dim_candidates, [q[1] for q in quantiles], marker='o', color='white', s=30, zorder=3)\n",
    "ax.vlines(latent_dim_candidates, [q[0] for q in quantiles], [q[2] for q in quantiles], color='k', linestyle='-', lw=5)\n",
    "ax.axhline(y=0.0, color='k', linestyle='--', lw=5)\n",
    "\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_ylabel(r\"Pearson correlation $r$\" + \"\\nPseudo-immune and titer distance\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "\n",
    "\n",
    "# Parameter count\n",
    "ax = fig.add_subplot(spec[1]); axes.append(ax)\n",
    "#ax.plot(latent_dim_candidates, parameter_count, zorder=-1, color=\"lightgrey\")\n",
    "parameter_count = [get_parameter_count(posteriors[D]) for D in latent_dim_candidates]\n",
    "ax.scatter(latent_dim_candidates, parameter_count, color=\"red\", ec=\"k\", s=120, label=\"Latent factor model\")\n",
    "ax.axhline(mlr_fixed_count(),linestyle=\"--\", color=\"#B3B3B3\", label=\"Fixed fitness\")\n",
    "ax.axhline(mlr_time_count(),linestyle=\"--\", color=\"#666666\", label=\"Time-varying fitness\")\n",
    "ax.set_ylabel(\"Number of parameters\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "ax.legend()\n",
    "\n",
    "# BIC\n",
    "ax = fig.add_subplot(spec[3]); axes.append(ax)\n",
    "ax.scatter(latent_dim_candidates, bic, color=\"red\", ec=\"k\", s=90)\n",
    "ax.set_ylabel(\"BIC\")\n",
    "ax.set_xlabel(\"Latent dimension\")\n",
    "ax.set_xticks(latent_dim_candidates)\n",
    "ax.set_yscale(\"log\")\n",
    "ax_labels = [\"A\", \"B\", \"C\", \"D\"] \n",
    "\n",
    "for ax, ax_label in zip(axes, ax_labels):\n",
    "    ax.text(-0.2, 1.05, ax_label + \".\", transform=ax.transAxes, size=36, weight='bold')\n",
    "\n",
    "fig.savefig(\"../manuscript/supplementary_figures/loss_by_latent_dimension.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
